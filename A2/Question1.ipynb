{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 251407,
     "status": "ok",
     "timestamp": 1615839939713,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "5cfoZB4P5TyP"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2LPnFUb5TyP"
   },
   "source": [
    "Similar to the character encoding used in the character-level RNN\n",
    "tutorials, we will be representing each word in a language as a one-hot\n",
    "vector, or giant vector of zeros except for a single one (at the index\n",
    "of the word). Compared to the dozens of characters that might exist in a\n",
    "language, there are many many more words, so the encoding vector is much\n",
    "larger. We will however cheat a bit and trim the data to only use a few\n",
    "thousand words per language.\n",
    "\n",
    ".. figure:: /_static/img/seq-seq-images/word-encoding.png\n",
    "   :alt:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSgTy9rL5TyQ"
   },
   "source": [
    "We'll need a unique index per word to use as the inputs and targets of\n",
    "the networks later. To keep track of all this we will use a helper class\n",
    "called ``Lang`` which has word → index (``word2index``) and index → word\n",
    "(``index2word``) dictionaries, as well as a count of each word\n",
    "``word2count`` to use to later replace rare words.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252793,
     "status": "ok",
     "timestamp": 1615839941188,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "2BAvHan-5TyQ",
    "outputId": "b24bcaf5-9356-478b-cba0-ef448b041c40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165602"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in input language\n",
    "\n",
    "otherLang = []\n",
    "\n",
    "with open('training/news-commentary-v9.ru-en.ru', 'rb') as f:\n",
    "    for line in f:\n",
    "        \n",
    "        line = str(line, 'utf-8') \n",
    "        line = unicodedata.normalize(\"NFKD\", line)\n",
    "        line = line.strip('\\n')\n",
    "        otherLang.append(line)\n",
    "len(otherLang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253212,
     "status": "ok",
     "timestamp": 1615839941619,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "2PldOCR45TyR",
    "outputId": "c5b4c014-5ffe-4bf1-f5c6-84cfeeb730d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165602"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in target language\n",
    "\n",
    "engLang = []\n",
    "\n",
    "with open('training/news-commentary-v9.ru-en.en', \"rb\") as f:\n",
    "    for line in f:\n",
    "        line = str(line, 'utf-8') \n",
    "        line = unicodedata.normalize(\"NFKD\", line)\n",
    "        line = line.strip('\\n')\n",
    "        engLang.append(line)\n",
    "\n",
    "len(engLang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 253484,
     "status": "ok",
     "timestamp": 1615839941893,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "exbekw8K5TyR"
   },
   "outputs": [],
   "source": [
    "#Combine sentences as pair, tab separated in text file\n",
    "\n",
    "count = 0\n",
    "combinedPairs = []\n",
    "\n",
    "for line in range(len(otherLang)):\n",
    "    s = (\"% s\\t% s\" % (otherLang[count], engLang[count]))\n",
    "    \n",
    "    combinedPairs.append(s)\n",
    "   \n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 253483,
     "status": "ok",
     "timestamp": 1615839941894,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "USHig-wW5TyS"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thUrpDx_5TyS"
   },
   "source": [
    "The files are all in Unicode, to simplify we will turn Unicode\n",
    "characters to ASCII, make everything lowercase, and trim most\n",
    "punctuation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 253480,
     "status": "ok",
     "timestamp": 1615839941895,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "XKkFod9A5TyS"
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "#     s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)   #######Comment this part out if handling russian files\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XssJYmww5TyS"
   },
   "source": [
    "To read the data file we will split the file into lines, and then split\n",
    "lines into pairs. The files are all English → Other Language, so if we\n",
    "want to translate from Other Language → English I added the ``reverse``\n",
    "flag to reverse the pairs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 253478,
     "status": "ok",
     "timestamp": 1615839941895,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "lKRO6tqp5TyT"
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in combinedPairs]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J40vq7MN5TyT"
   },
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "-  Read text file and split into lines, split lines into pairs\n",
    "-  Normalize text, filter by length and content\n",
    "-  Make word lists from sentences in pairs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data\n",
    "-----------\n",
    "\n",
    "Below are 2 versions of prepareData, the first version randomly selects 10% of the dataset for testing. The second version uses 5 Folds. Comment out the version that is not in use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 270855,
     "status": "ok",
     "timestamp": 1615839959283,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "DhmOI5lt5TyT",
    "outputId": "401dc3ba-6bf7-4810-9d83-d877325ea856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 165602 sentence pairs\n",
      "Number of test pairs: 16560\n",
      "Number of test cases (sent + list): 16549\n",
      "Number of train pairs: 148820\n",
      "Counting words...\n",
      "Counted words:\n",
      "ru 204723\n",
      "eng 100215\n",
      "('корпорация general electric, например, сокращает количество функции, обеспечиваемых ее медицинским оборудованием, до обязательного минимума, чтобы обеспечить отдаленные сельские клиники по всему развивающемуся миру .', 'general electric, for example, is cutting down the functions provided by its medical equipment to only what is strictly useful in order to supply remote rural clinics across the developing world .')\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    # collect test pairs\n",
    "    num_test = int(len(pairs)*0.1)\n",
    "    print(\"Number of test pairs:\", num_test)\n",
    "    random.shuffle(pairs)\n",
    "    test_pairs = pairs[:num_test]\n",
    "    set_test_eng = set([sent_eng for sent_eng, _ in test_pairs])\n",
    "    \n",
    "    test_pair_dict = {}\n",
    "    for sent_eng, sent_fre in pairs:\n",
    "        if sent_eng not in set_test_eng:\n",
    "            continue \n",
    "        elif sent_eng not in test_pair_dict:\n",
    "            test_pair_dict[sent_eng] = set([sent_fre])\n",
    "        else:\n",
    "            test_pair_dict[sent_eng].add(sent_fre)\n",
    "    test_pairs = [(sent_eng, list(test_pair_dict[sent_eng])) for sent_eng in test_pair_dict]\n",
    "    print(\"Number of test cases (sent + list):\", len(test_pairs))\n",
    "    \n",
    "    # collect train pairs\n",
    "    train_pairs = [(sent_eng, sent_fre) for sent_eng, sent_fre in pairs[num_test:] if sent_eng not in set_test_eng]\n",
    "    print(\"Number of train pairs:\", len(train_pairs))\n",
    "    \n",
    "    print(\"Counting words...\")\n",
    "    for pair in train_pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, train_pairs, test_pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, train_pairs, test_pairs = prepareData('ru', 'eng', False)\n",
    "print(random.choice(train_pairs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 270844,
     "status": "ok",
     "timestamp": 1615839959283,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "2oQR-qkR5TyY",
    "outputId": "7e8c8521-0e5e-46f8-ec22-427056d35837"
   },
   "source": [
    "Prepare 5 Fold Data\n",
    "-----------\n",
    "\n",
    "Use this code to randomly split the dataset into 5 subsets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepareData(lang1, lang2, reverse=False):\n",
    "#     input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "#     print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "#     input_lang_1 = input_lang\n",
    "#     input_lang_2 = input_lang\n",
    "#     input_lang_3 = input_lang\n",
    "#     input_lang_4 = input_lang\n",
    "#     input_lang_5 = input_lang\n",
    "    \n",
    "#     output_lang_1 = output_lang\n",
    "#     output_lang_2 = output_lang\n",
    "#     output_lang_3 = output_lang\n",
    "#     output_lang_4 = output_lang\n",
    "#     output_lang_5 = output_lang\n",
    "    \n",
    "#     # collect test pairs\n",
    "#     num_test = int(len(pairs)*0.2)\n",
    "#     print(\"Number of test pairs per fold:\", num_test)\n",
    "#     print(\"\\n\")\n",
    "#     random.shuffle(pairs)\n",
    "    \n",
    "#     ###########################################    Fold 1    ##########################################################\n",
    "#     test_pairs_1 = pairs[:num_test]\n",
    "#     set_test_eng_1 = set([sent_eng for sent_eng, _ in test_pairs_1])\n",
    "    \n",
    "#     test_pair_dict_1 = {}\n",
    "#     for sent_eng, sent_fre in pairs:\n",
    "#         if sent_eng not in set_test_eng_1:\n",
    "#             continue \n",
    "#         elif sent_eng not in test_pair_dict_1:\n",
    "#             test_pair_dict_1[sent_eng] = set([sent_fre])\n",
    "#         else:\n",
    "#             test_pair_dict_1[sent_eng].add(sent_fre)\n",
    "#     test_pairs_1 = [(sent_eng, list(test_pair_dict_1[sent_eng])) for sent_eng in test_pair_dict_1]\n",
    "#     print(\"Number of test cases (sent + list) for Fold 1:\", len(test_pairs_1))\n",
    "    \n",
    "#     # collect train pairs\n",
    "#     train_pairs_1 = [(sent_eng, sent_fre) for sent_eng, sent_fre in pairs[num_test:] if sent_eng not in set_test_eng_1]\n",
    "#     print(\"Number of train pairs for Fold 1:\", len(train_pairs_1))\n",
    "    \n",
    "#     print(\"Counting words...\")\n",
    "#     for pair in train_pairs_1:\n",
    "#         input_lang_1.addSentence(pair[0])\n",
    "#         output_lang_1.addSentence(pair[1])\n",
    "#     print(\"Counted words for Fold 1:\")\n",
    "#     print(input_lang_1.name, input_lang_1.n_words)\n",
    "#     print(output_lang_1.name, output_lang_1.n_words)\n",
    "#     print(\"\\n\")\n",
    "    \n",
    "#     ###########################################    Fold 2    ##########################################################\n",
    "#     test_pairs_2 = pairs[num_test:num_test*2]\n",
    "#     set_test_eng_2 = set([sent_eng for sent_eng, _ in test_pairs_2])\n",
    "    \n",
    "#     test_pair_dict_2 = {}\n",
    "#     for sent_eng, sent_fre in pairs:\n",
    "#         if sent_eng not in set_test_eng_2:\n",
    "#             continue \n",
    "#         elif sent_eng not in test_pair_dict_2:\n",
    "#             test_pair_dict_2[sent_eng] = set([sent_fre])\n",
    "#         else:\n",
    "#             test_pair_dict_2[sent_eng].add(sent_fre)\n",
    "#     test_pairs_2 = [(sent_eng, list(test_pair_dict_2[sent_eng])) for sent_eng in test_pair_dict_2]\n",
    "#     print(\"Number of test cases (sent + list) for Fold 2:\", len(test_pairs_2))\n",
    "    \n",
    "#     # collect train pairs\n",
    "#     pairs_2 = pairs[:]\n",
    "#     del pairs_2[num_test:num_test*2]\n",
    "    \n",
    "#     train_pairs_2 = [(sent_eng, sent_fre) for sent_eng, sent_fre in pairs_2 if sent_eng not in set_test_eng_2]\n",
    "#     print(\"Number of train pairs for Fold 2:\", len(train_pairs_2))\n",
    "    \n",
    "#     print(\"Counting words...\")\n",
    "#     for pair in train_pairs_2:\n",
    "#         input_lang_2.addSentence(pair[0])\n",
    "#         output_lang_2.addSentence(pair[1])\n",
    "#     print(\"Counted words for Fold 2:\")\n",
    "#     print(input_lang_2.name, input_lang_2.n_words)\n",
    "#     print(output_lang_2.name, output_lang_2.n_words)\n",
    "#     print(\"\\n\")\n",
    "    \n",
    "#     ###########################################    Fold 3    ##########################################################\n",
    "#     test_pairs_3 = pairs[num_test*2:num_test*3]\n",
    "#     set_test_eng_3 = set([sent_eng for sent_eng, _ in test_pairs_3])\n",
    "    \n",
    "#     test_pair_dict_3 = {}\n",
    "#     for sent_eng, sent_fre in pairs:\n",
    "#         if sent_eng not in set_test_eng_3:\n",
    "#             continue \n",
    "#         elif sent_eng not in test_pair_dict_3:\n",
    "#             test_pair_dict_3[sent_eng] = set([sent_fre])\n",
    "#         else:\n",
    "#             test_pair_dict_3[sent_eng].add(sent_fre)\n",
    "#     test_pairs_3 = [(sent_eng, list(test_pair_dict_3[sent_eng])) for sent_eng in test_pair_dict_3]\n",
    "#     print(\"Number of test cases (sent + list) for Fold 3:\", len(test_pairs_3))\n",
    "    \n",
    "#     # collect train pairs\n",
    "#     pairs_3 = pairs[:]\n",
    "#     del pairs_3[num_test*2:num_test*3]\n",
    "    \n",
    "#     train_pairs_3 = [(sent_eng, sent_fre) for sent_eng, sent_fre in pairs_3 if sent_eng not in set_test_eng_3]\n",
    "#     print(\"Number of train pairs for Fold 3:\", len(train_pairs_3))\n",
    "    \n",
    "#     print(\"Counting words...\")\n",
    "#     for pair in train_pairs_3:\n",
    "#         input_lang_3.addSentence(pair[0])\n",
    "#         output_lang_3.addSentence(pair[1])\n",
    "#     print(\"Counted words for Fold 3:\")\n",
    "#     print(input_lang_3.name, input_lang_3.n_words)\n",
    "#     print(output_lang_3.name, output_lang_3.n_words)\n",
    "#     print(\"\\n\")\n",
    "    \n",
    "#     ###########################################    Fold 4    ##########################################################\n",
    "#     test_pairs_4 = pairs[num_test*3:num_test*4]\n",
    "#     set_test_eng_4 = set([sent_eng for sent_eng, _ in test_pairs_4])\n",
    "    \n",
    "#     test_pair_dict_4 = {}\n",
    "#     for sent_eng, sent_fre in pairs:\n",
    "#         if sent_eng not in set_test_eng_4:\n",
    "#             continue \n",
    "#         elif sent_eng not in test_pair_dict_4:\n",
    "#             test_pair_dict_4[sent_eng] = set([sent_fre])\n",
    "#         else:\n",
    "#             test_pair_dict_4[sent_eng].add(sent_fre)\n",
    "#     test_pairs_4 = [(sent_eng, list(test_pair_dict_4[sent_eng])) for sent_eng in test_pair_dict_4]\n",
    "#     print(\"Number of test cases (sent + list) for Fold 4:\", len(test_pairs_4))\n",
    "    \n",
    "#     # collect train pairs\n",
    "#     pairs_4 = pairs[:]\n",
    "#     del pairs_4[num_test*3:num_test*4]\n",
    "    \n",
    "#     train_pairs_4 = [(sent_eng, sent_fre) for sent_eng, sent_fre in pairs_4 if sent_eng not in set_test_eng_4]\n",
    "#     print(\"Number of train pairs for Fold 4:\", len(train_pairs_4))\n",
    "    \n",
    "#     print(\"Counting words...\")\n",
    "#     for pair in train_pairs_4:\n",
    "#         input_lang_4.addSentence(pair[0])\n",
    "#         output_lang_4.addSentence(pair[1])\n",
    "#     print(\"Counted words for Fold 4:\")\n",
    "#     print(input_lang_4.name, input_lang_4.n_words)\n",
    "#     print(output_lang_4.name, output_lang_4.n_words)\n",
    "#     print(\"\\n\")\n",
    "    \n",
    "#     ###########################################    Fold 5    ##########################################################\n",
    "#     test_pairs_5 = pairs[num_test*4:]\n",
    "#     set_test_eng_5 = set([sent_eng for sent_eng, _ in test_pairs_5])\n",
    "    \n",
    "#     test_pair_dict_5 = {}\n",
    "#     for sent_eng, sent_fre in pairs:\n",
    "#         if sent_eng not in set_test_eng_5:\n",
    "#             continue \n",
    "#         elif sent_eng not in test_pair_dict_5:\n",
    "#             test_pair_dict_5[sent_eng] = set([sent_fre])\n",
    "#         else:\n",
    "#             test_pair_dict_5[sent_eng].add(sent_fre)\n",
    "#     test_pairs_5 = [(sent_eng, list(test_pair_dict_5[sent_eng])) for sent_eng in test_pair_dict_5]\n",
    "#     print(\"Number of test cases (sent + list) for Fold 5:\", len(test_pairs_5))\n",
    "    \n",
    "#     # collect train pairs\n",
    "#     pairs_5 = pairs[:]\n",
    "#     del pairs_5[num_test*4:]\n",
    "    \n",
    "#     train_pairs_5 = [(sent_eng, sent_fre) for sent_eng, sent_fre in pairs_5 if sent_eng not in set_test_eng_5]\n",
    "#     print(\"Number of train pairs for Fold 5:\", len(train_pairs_5))\n",
    "    \n",
    "#     print(\"Counting words...\")\n",
    "#     for pair in train_pairs_5:\n",
    "#         input_lang_5.addSentence(pair[0])\n",
    "#         output_lang_5.addSentence(pair[1])\n",
    "#     print(\"Counted words for Fold 5:\")\n",
    "#     print(input_lang_5.name, input_lang_5.n_words)\n",
    "#     print(output_lang_5.name, output_lang_5.n_words)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     return input_lang_1, input_lang_2, input_lang_3, input_lang_4, input_lang_5,\\\n",
    "#     output_lang_1, output_lang_2, output_lang_3, output_lang_4, output_lang_5,\\\n",
    "#     train_pairs_1, train_pairs_2, train_pairs_3, train_pairs_4, train_pairs_5,\\\n",
    "#     test_pairs_1, test_pairs_2, test_pairs_3, test_pairs_4, test_pairs_5\n",
    "\n",
    "\n",
    "# input_lang_1, input_lang_2, input_lang_3, input_lang_4, input_lang_5,\\\n",
    "# output_lang_1, output_lang_2, output_lang_3, output_lang_4, output_lang_5,\\\n",
    "# train_pairs_1, train_pairs_2, train_pairs_3, train_pairs_4, train_pairs_5,\\\n",
    "# test_pairs_1, test_pairs_2, test_pairs_3, test_pairs_4, test_pairs_5, = prepareData('de', 'eng', False)\n",
    "# print(random.choice(train_pairs_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTNijP4W5Tyb"
   },
   "source": [
    "The Seq2Seq Model\n",
    "=================\n",
    "\n",
    "A Recurrent Neural Network, or RNN, is a network that operates on a\n",
    "sequence and uses its own output as input for subsequent steps.\n",
    "\n",
    "A `Sequence to Sequence network <https://arxiv.org/abs/1409.3215>`__, or\n",
    "seq2seq network, or `Encoder Decoder\n",
    "network <https://arxiv.org/pdf/1406.1078v3.pdf>`__, is a model\n",
    "consisting of two RNNs called the encoder and decoder. The encoder reads\n",
    "an input sequence and outputs a single vector, and the decoder reads\n",
    "that vector to produce an output sequence.\n",
    "\n",
    ".. figure:: /_static/img/seq-seq-images/seq2seq.png\n",
    "   :alt:\n",
    "\n",
    "Unlike sequence prediction with a single RNN, where every input\n",
    "corresponds to an output, the seq2seq model frees us from sequence\n",
    "length and order, which makes it ideal for translation between two\n",
    "languages.\n",
    "\n",
    "Consider the sentence \"Je ne suis pas le chat noir\" → \"I am not the\n",
    "black cat\". Most of the words in the input sentence have a direct\n",
    "translation in the output sentence, but are in slightly different\n",
    "orders, e.g. \"chat noir\" and \"black cat\". Because of the \"ne/pas\"\n",
    "construction there is also one more word in the input sentence. It would\n",
    "be difficult to produce a correct translation directly from the sequence\n",
    "of input words.\n",
    "\n",
    "With a seq2seq model the encoder creates a single vector which, in the\n",
    "ideal case, encodes the \"meaning\" of the input sequence into a single\n",
    "vector — a single point in some N dimensional space of sentences.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5C-jxBC5Tyb"
   },
   "source": [
    "The Encoder\n",
    "-----------\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for\n",
    "every word from the input sentence. For every input word the encoder\n",
    "outputs a vector and a hidden state, and uses the hidden state for the\n",
    "next input word.\n",
    "\n",
    ".. figure:: /_static/img/seq-seq-images/encoder-network.png\n",
    "   :alt:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 270842,
     "status": "ok",
     "timestamp": 1615839959284,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "-kbR1enh5Tyb"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2dUapv-5Tyc"
   },
   "source": [
    "The Decoder\n",
    "-----------\n",
    "\n",
    "The decoder is another RNN that takes the encoder output vector(s) and\n",
    "outputs a sequence of words to create the translation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5kfDPGN5Tyc"
   },
   "source": [
    "Simple Decoder\n",
    "^^^^^^^^^^^^^^\n",
    "\n",
    "In the simplest seq2seq decoder we use only last output of the encoder.\n",
    "This last output is sometimes called the *context vector* as it encodes\n",
    "context from the entire sequence. This context vector is used as the\n",
    "initial hidden state of the decoder.\n",
    "\n",
    "At every step of decoding, the decoder is given an input token and\n",
    "hidden state. The initial input token is the start-of-string ``<SOS>``\n",
    "token, and the first hidden state is the context vector (the encoder's\n",
    "last hidden state).\n",
    "\n",
    ".. figure:: /_static/img/seq-seq-images/decoder-network.png\n",
    "   :alt:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 270840,
     "status": "ok",
     "timestamp": 1615839959285,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "9WDIZUm05Tyc"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npti0Q1q5Tyc"
   },
   "source": [
    "I encourage you to train and observe the results of this model, but to\n",
    "save space we'll be going straight for the gold and introducing the\n",
    "Attention Mechanism.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pg_Qdwo65Tyc"
   },
   "source": [
    "Attention Decoder\n",
    "^^^^^^^^^^^^^^^^^\n",
    "\n",
    "If only the context vector is passed betweeen the encoder and decoder,\n",
    "that single vector carries the burden of encoding the entire sentence.\n",
    "\n",
    "Attention allows the decoder network to \"focus\" on a different part of\n",
    "the encoder's outputs for every step of the decoder's own outputs. First\n",
    "we calculate a set of *attention weights*. These will be multiplied by\n",
    "the encoder output vectors to create a weighted combination. The result\n",
    "(called ``attn_applied`` in the code) should contain information about\n",
    "that specific part of the input sequence, and thus help the decoder\n",
    "choose the right output words.\n",
    "\n",
    ".. figure:: https://i.imgur.com/1152PYf.png\n",
    "   :alt:\n",
    "\n",
    "Calculating the attention weights is done with another feed-forward\n",
    "layer ``attn``, using the decoder's input and hidden state as inputs.\n",
    "Because there are sentences of all sizes in the training data, to\n",
    "actually create and train this layer we have to choose a maximum\n",
    "sentence length (input length, for encoder outputs) that it can apply\n",
    "to. Sentences of the maximum length will use all the attention weights,\n",
    "while shorter sentences will only use the first few.\n",
    "\n",
    ".. figure:: /_static/img/seq-seq-images/attention-decoder-network.png\n",
    "   :alt:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 270835,
     "status": "ok",
     "timestamp": 1615839959285,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "QheCtmqQ5Tyc"
   },
   "outputs": [],
   "source": [
    "#Number of words, use large number to avoid going out of range\n",
    "MAX_LENGTH = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 270833,
     "status": "ok",
     "timestamp": 1615839959286,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "GseRRiQN5Tyd"
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LD2LGZVN5Tyd"
   },
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>There are other forms of attention that work around the length\n",
    "  limitation by using a relative position approach. Read about \"local\n",
    "  attention\" in `Effective Approaches to Attention-based Neural Machine\n",
    "  Translation <https://arxiv.org/abs/1508.04025>`__.</p></div>\n",
    "\n",
    "Training\n",
    "========\n",
    "\n",
    "Preparing Training Data\n",
    "-----------------------\n",
    "\n",
    "To train, for each pair we will need an input tensor (indexes of the\n",
    "words in the input sentence) and target tensor (indexes of the words in\n",
    "the target sentence). While creating these vectors we will append the\n",
    "EOS token to both sequences.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 270831,
     "status": "ok",
     "timestamp": 1615839959286,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "lWGZbrOy5Tyd"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    \n",
    "    #If using K-Folds, change input_lang to input_lang_1/input_lang_2/input_lang_3/input_lang_4/input_lang_5 accordingly\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    \n",
    "    #If using K-Folds, change output_lang to output_lang_1/output_lang_2/output_lang_3/output_lang_4/output_lang_5 accordingly\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wknZPW4E5Tyd"
   },
   "source": [
    "Training the Model\n",
    "------------------\n",
    "\n",
    "To train we run the input sentence through the encoder, and keep track\n",
    "of every output and the latest hidden state. Then the decoder is given\n",
    "the ``<SOS>`` token as its first input, and the last hidden state of the\n",
    "encoder as its first hidden state.\n",
    "\n",
    "\"Teacher forcing\" is the concept of using the real target outputs as\n",
    "each next input, instead of using the decoder's guess as the next input.\n",
    "Using teacher forcing causes it to converge faster but `when the trained\n",
    "network is exploited, it may exhibit\n",
    "instability <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf>`__.\n",
    "\n",
    "You can observe outputs of teacher-forced networks that read with\n",
    "coherent grammar but wander far from the correct translation -\n",
    "intuitively it has learned to represent the output grammar and can \"pick\n",
    "up\" the meaning once the teacher tells it the first few words, but it\n",
    "has not properly learned how to create the sentence from the translation\n",
    "in the first place.\n",
    "\n",
    "Because of the freedom PyTorch's autograd gives us, we can randomly\n",
    "choose to use teacher forcing or not with a simple if statement. Turn\n",
    "``teacher_forcing_ratio`` up to use more of it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 270832,
     "status": "ok",
     "timestamp": 1615839959288,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "nR9r2E1q5Tyd"
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaEZAxSB5Tyd"
   },
   "source": [
    "This is a helper function to print time elapsed and estimated time\n",
    "remaining given the current time and progress %.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 270832,
     "status": "ok",
     "timestamp": 1615839959290,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "SVbZKDtV5Tyd"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LRECQJ05Tye"
   },
   "source": [
    "The whole training process looks like this:\n",
    "\n",
    "-  Start a timer\n",
    "-  Initialize optimizers and criterion\n",
    "-  Create set of training pairs\n",
    "-  Start empty losses array for plotting\n",
    "\n",
    "Then we call ``train`` many times and occasionally print the progress (%\n",
    "of examples, time so far, estimated time) and average loss.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 270833,
     "status": "ok",
     "timestamp": 1615839959292,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "IhP-kK_Y5Tye"
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    #If using K-Folds, change train_pairs to train_pairs_1/train_pairs_2/train_pairs_3/train_pairs_4/train_pairs_5\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNn6-sQ85Tye"
   },
   "source": [
    "Plotting results\n",
    "----------------\n",
    "\n",
    "Plotting is done with matplotlib, using the array of loss values\n",
    "``plot_losses`` saved while training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 270832,
     "status": "ok",
     "timestamp": 1615839959293,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "lgEZvhSy5Tye"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xY7rQntZ5Tye"
   },
   "source": [
    "Evaluation\n",
    "==========\n",
    "\n",
    "Evaluation is mostly the same as training, but there are no targets so\n",
    "we simply feed the decoder's predictions back to itself for each step.\n",
    "Every time it predicts a word we add it to the output string, and if it\n",
    "predicts the EOS token we stop there. We also store the decoder's\n",
    "attention outputs for display later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 270830,
     "status": "ok",
     "timestamp": 1615839959294,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "-AcMPWr_5Tye"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        #If using K-Folds, change input_lang to input_lang_1/input_lang_2/input_lang_3/input_lang_4/input_lang_5 accordingly\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        \n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                \n",
    "                #If using K-Folds, change output_lang to output_lang_1/output_lang_2/output_lang_3/output_lang_4/output_lang_5 accordingly\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 271080,
     "status": "ok",
     "timestamp": 1615839959548,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "uh3blCyt5Tye"
   },
   "outputs": [],
   "source": [
    "class BeamSearchNode(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
    "        '''\n",
    "        :param hiddenstate:\n",
    "        :param previousNode:\n",
    "        :param wordId:\n",
    "        :param logProb:\n",
    "        :param length:\n",
    "        '''\n",
    "        self.h = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordid = wordId\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "\n",
    "    def eval(self, alpha=1.0):\n",
    "        reward = 0\n",
    "        # Add here a function for shaping a reward\n",
    "        # Normalization\n",
    "        return self.logp / float(self.leng - 1 +1e-6) + alpha * reward\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.eval() < other.eval()\n",
    "    \n",
    "    \n",
    "from queue import PriorityQueue\n",
    "\n",
    "def evaluate_beam_search(encoder, decoder, sentence, max_length=MAX_LENGTH, beam_size=2):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        #If using K-Folds, change input_lang to input_lang_1/input_lang_2/input_lang_3/input_lang_4/input_lang_5 accordingly\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        \n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # Number of sentence to generate\n",
    "        endnodes = []\n",
    "        number_required = 1\n",
    "        \n",
    "        # starting node -  hidden vector, previous node, word id, logp, length\n",
    "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        # start the queue\n",
    "        nodes.put((-node.eval(), node))\n",
    "        qsize = 1\n",
    "      \n",
    "        # start beam search\n",
    "        while True:\n",
    "            # give up when decoding takes too long\n",
    "            if qsize > 2000: break\n",
    "\n",
    "            # fetch the best node\n",
    "            score, n = nodes.get()\n",
    "            decoder_input = n.wordid\n",
    "            decoder_hidden = n.h\n",
    "\n",
    "            if n.wordid.item() == EOS_token and n.prevNode != None:\n",
    "                endnodes.append((score, n))\n",
    "                # if we reached maximum # of sentences required\n",
    "                if len(endnodes) >= number_required:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            ### Uncomment this part for max length\n",
    "#             elif n.leng > max_length:\n",
    "#                 continue\n",
    "\n",
    "            # decode for one step using decoder\n",
    "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
    "            log_prob, indexes = torch.topk(decoder_output, beam_size)\n",
    "            nextnodes = []\n",
    "\n",
    "            for new_k in range(beam_size):\n",
    "                decoded_t = indexes[0][new_k].view(1, -1)\n",
    "                log_p = log_prob[0][new_k].item()\n",
    "\n",
    "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
    "                score = -node.eval()\n",
    "                nextnodes.append((score, node))\n",
    "\n",
    "            # put them into queue\n",
    "            for i in range(len(nextnodes)):\n",
    "                score, nn = nextnodes[i]\n",
    "                nodes.put((score, nn))\n",
    "                \n",
    "            # increase qsize\n",
    "            qsize += len(nextnodes) - 1\n",
    "            \n",
    "        # choose nbest paths, back trace them\n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(number_required)]\n",
    "\n",
    "        _, n = endnodes[0]\n",
    "        utterance = []\n",
    "        \n",
    "        #If using K-Folds, change output_lang to output_lang_1/output_lang_2/output_lang_3/output_lang_4/output_lang_5 accordingly\n",
    "        utterance.append(output_lang.index2word[n.wordid.item()])\n",
    "        \n",
    "        # back trace\n",
    "        while n.prevNode != None:\n",
    "            n = n.prevNode\n",
    "            \n",
    "            #If using K-Folds, change output_lang to output_lang_1/output_lang_2/output_lang_3/output_lang_4/output_lang_5 accordingly\n",
    "            utterance.append(output_lang.index2word[n.wordid.item()])\n",
    "\n",
    "        utterance = utterance[::-1]\n",
    "            \n",
    "    return utterance, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfaWqFe_5Tyf"
   },
   "source": [
    "We can evaluate random sentences from the training set and print out the\n",
    "input, target, and output to make some subjective quality judgements:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 271078,
     "status": "ok",
     "timestamp": 1615839959548,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "qUynSPNS5Tyf"
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 271822,
     "status": "ok",
     "timestamp": 1615839960293,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "ZiURxw4O5Tyf"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu(encoder, decoder):\n",
    "    references, candidates = [], []\n",
    "    \n",
    "    #If using K-Folds, change test_pairs to test_pairs_1/test_pairs_2/test_pairs_3/test_pairs_4/test_pairs_5\n",
    "    for sent_eng, sents_fre in test_pairs:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in sents_fre]\n",
    "        output_words, _ = evaluate(encoder, decoder, sent_eng)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    score = corpus_bleu(references, candidates)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 271821,
     "status": "ok",
     "timestamp": 1615839960294,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "RWPwMA_M5Tyf"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluateBleu_beam_search(encoder, decoder, beam_size):\n",
    "    references, candidates = [], []\n",
    "    \n",
    "    #If using K-Folds, change test_pairs to test_pairs_1/test_pairs_2/test_pairs_3/test_pairs_4/test_pairs_5\n",
    "    for sent_eng, sents_fre in test_pairs:\n",
    "        sents_fre = [sent_fre.split(' ') for sent_fre in sents_fre]\n",
    "        output_words, _ = evaluate_beam_search(encoder, decoder, sent_eng, beam_size=beam_size)\n",
    "        references.append(sents_fre)\n",
    "        candidates.append(output_words)\n",
    "    score = corpus_bleu(references, candidates)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJ0H4YRQ5Tyf"
   },
   "source": [
    "Training and Evaluating\n",
    "=======================\n",
    "\n",
    "With all these helper functions in place (it looks like extra work, but\n",
    "it makes it easier to run multiple experiments) we can actually\n",
    "initialize a network and start training.\n",
    "\n",
    "Remember that the input sentences were heavily filtered. For this small\n",
    "dataset we can use relatively small networks of 256 hidden nodes and a\n",
    "single GRU layer. After about 40 minutes on a MacBook CPU we'll get some\n",
    "reasonable results.\n",
    "\n",
    ".. Note::\n",
    "   If you run this notebook you can train, interrupt the kernel,\n",
    "   evaluate, and continue training later. Comment out the lines where the\n",
    "   encoder and decoder are initialized and run ``trainIters`` again.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6338854,
     "status": "ok",
     "timestamp": 1615846027333,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "SrIx4r_L5Tyf",
    "outputId": "fe025c10-0ae6-4d63-c290-ebfad183be3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 37s (- 186m 23s) (100 0%) 7.3717\n",
      "1m 9s (- 173m 1s) (200 0%) 7.1511\n",
      "1m 41s (- 168m 15s) (300 1%) 6.7088\n",
      "2m 15s (- 166m 58s) (400 1%) 6.4302\n",
      "2m 47s (- 164m 39s) (500 1%) 6.2151\n",
      "3m 22s (- 165m 0s) (600 2%) 6.6940\n",
      "3m 58s (- 166m 22s) (700 2%) 6.7523\n",
      "4m 31s (- 165m 27s) (800 2%) 6.5138\n",
      "5m 4s (- 163m 53s) (900 3%) 6.2509\n",
      "5m 36s (- 162m 48s) (1000 3%) 5.9258\n",
      "6m 11s (- 162m 42s) (1100 3%) 6.1200\n",
      "6m 42s (- 161m 8s) (1200 4%) 5.9820\n",
      "7m 19s (- 161m 38s) (1300 4%) 6.1008\n",
      "7m 52s (- 161m 1s) (1400 4%) 6.0023\n",
      "8m 27s (- 160m 46s) (1500 5%) 5.8054\n",
      "9m 1s (- 160m 3s) (1600 5%) 5.8113\n",
      "9m 33s (- 159m 13s) (1700 5%) 6.3237\n",
      "10m 8s (- 158m 53s) (1800 6%) 6.2792\n",
      "10m 40s (- 157m 53s) (1900 6%) 5.5470\n",
      "11m 12s (- 156m 55s) (2000 6%) 5.7136\n",
      "11m 45s (- 156m 16s) (2100 7%) 6.0317\n",
      "12m 16s (- 155m 1s) (2200 7%) 5.6187\n",
      "12m 50s (- 154m 44s) (2300 7%) 6.1107\n",
      "13m 22s (- 153m 54s) (2400 8%) 5.2632\n",
      "13m 57s (- 153m 31s) (2500 8%) 6.1129\n",
      "14m 28s (- 152m 35s) (2600 8%) 5.6800\n",
      "15m 3s (- 152m 18s) (2700 9%) 6.4595\n",
      "15m 36s (- 151m 40s) (2800 9%) 5.8277\n",
      "16m 10s (- 151m 12s) (2900 9%) 5.7929\n",
      "16m 42s (- 150m 26s) (3000 10%) 6.1603\n",
      "17m 15s (- 149m 46s) (3100 10%) 5.4080\n",
      "17m 51s (- 149m 32s) (3200 10%) 5.9248\n",
      "18m 25s (- 149m 5s) (3300 11%) 5.8356\n",
      "18m 58s (- 148m 30s) (3400 11%) 5.8787\n",
      "19m 33s (- 148m 6s) (3500 11%) 5.8961\n",
      "20m 6s (- 147m 28s) (3600 12%) 5.8378\n",
      "20m 39s (- 146m 52s) (3700 12%) 6.0546\n",
      "21m 11s (- 146m 5s) (3800 12%) 5.3728\n",
      "21m 47s (- 145m 50s) (3900 13%) 5.8397\n",
      "22m 21s (- 145m 17s) (4000 13%) 5.6282\n",
      "22m 51s (- 144m 26s) (4100 13%) 5.6175\n",
      "23m 25s (- 143m 51s) (4200 14%) 6.0072\n",
      "24m 1s (- 143m 33s) (4300 14%) 5.8621\n",
      "24m 35s (- 143m 4s) (4400 14%) 5.8776\n",
      "25m 9s (- 142m 35s) (4500 15%) 6.0393\n",
      "25m 45s (- 142m 15s) (4600 15%) 5.6225\n",
      "26m 22s (- 141m 57s) (4700 15%) 6.1027\n",
      "26m 54s (- 141m 17s) (4800 16%) 5.3250\n",
      "27m 27s (- 140m 41s) (4900 16%) 5.3939\n",
      "28m 0s (- 140m 2s) (5000 16%) 5.7676\n",
      "28m 32s (- 139m 20s) (5100 17%) 5.7868\n",
      "29m 7s (- 138m 52s) (5200 17%) 5.6358\n",
      "29m 40s (- 138m 19s) (5300 17%) 5.4960\n",
      "30m 14s (- 137m 44s) (5400 18%) 5.9919\n",
      "30m 47s (- 137m 7s) (5500 18%) 5.7446\n",
      "31m 22s (- 136m 42s) (5600 18%) 5.7131\n",
      "31m 56s (- 136m 10s) (5700 19%) 6.2407\n",
      "32m 30s (- 135m 38s) (5800 19%) 5.8948\n",
      "33m 3s (- 135m 1s) (5900 19%) 5.6455\n",
      "33m 35s (- 134m 22s) (6000 20%) 5.5661\n",
      "34m 8s (- 133m 45s) (6100 20%) 5.5999\n",
      "34m 44s (- 133m 20s) (6200 20%) 5.7909\n",
      "35m 15s (- 132m 38s) (6300 21%) 5.7075\n",
      "35m 48s (- 132m 3s) (6400 21%) 5.7662\n",
      "36m 25s (- 131m 41s) (6500 21%) 5.5810\n",
      "36m 58s (- 131m 5s) (6600 22%) 5.7965\n",
      "37m 31s (- 130m 30s) (6700 22%) 5.8178\n",
      "38m 5s (- 129m 56s) (6800 22%) 5.8157\n",
      "38m 37s (- 129m 18s) (6900 23%) 5.8531\n",
      "39m 10s (- 128m 43s) (7000 23%) 5.5865\n",
      "39m 47s (- 128m 19s) (7100 23%) 5.9317\n",
      "40m 19s (- 127m 41s) (7200 24%) 5.6559\n",
      "40m 53s (- 127m 10s) (7300 24%) 5.6137\n",
      "41m 26s (- 126m 33s) (7400 24%) 5.5205\n",
      "41m 57s (- 125m 51s) (7500 25%) 5.4779\n",
      "42m 27s (- 125m 9s) (7600 25%) 5.6573\n",
      "43m 2s (- 124m 39s) (7700 25%) 5.8237\n",
      "43m 35s (- 124m 4s) (7800 26%) 5.4633\n",
      "44m 9s (- 123m 31s) (7900 26%) 5.7746\n",
      "44m 44s (- 123m 2s) (8000 26%) 5.9993\n",
      "45m 17s (- 122m 27s) (8100 27%) 5.7517\n",
      "45m 53s (- 122m 0s) (8200 27%) 6.0759\n",
      "46m 25s (- 121m 22s) (8300 27%) 5.8088\n",
      "46m 58s (- 120m 48s) (8400 28%) 5.5896\n",
      "47m 35s (- 120m 22s) (8500 28%) 5.7481\n",
      "48m 8s (- 119m 47s) (8600 28%) 5.4092\n",
      "48m 45s (- 119m 21s) (8700 28%) 5.9904\n",
      "49m 19s (- 118m 48s) (8800 29%) 5.9747\n",
      "49m 54s (- 118m 20s) (8900 29%) 5.9800\n",
      "50m 26s (- 117m 41s) (9000 30%) 5.4576\n",
      "50m 57s (- 117m 2s) (9100 30%) 5.3539\n",
      "51m 28s (- 116m 23s) (9200 30%) 5.7967\n",
      "52m 2s (- 115m 50s) (9300 31%) 5.7512\n",
      "52m 31s (- 115m 7s) (9400 31%) 5.4903\n",
      "53m 5s (- 114m 32s) (9500 31%) 5.6366\n",
      "53m 40s (- 114m 3s) (9600 32%) 5.7987\n",
      "54m 14s (- 113m 30s) (9700 32%) 5.8285\n",
      "54m 48s (- 112m 59s) (9800 32%) 5.8500\n",
      "55m 25s (- 112m 31s) (9900 33%) 5.8436\n",
      "55m 59s (- 111m 58s) (10000 33%) 5.9258\n",
      "56m 34s (- 111m 28s) (10100 33%) 5.8892\n",
      "57m 9s (- 110m 57s) (10200 34%) 5.8178\n",
      "57m 45s (- 110m 27s) (10300 34%) 6.2899\n",
      "58m 20s (- 109m 57s) (10400 34%) 6.0339\n",
      "58m 54s (- 109m 24s) (10500 35%) 5.8049\n",
      "59m 28s (- 108m 51s) (10600 35%) 5.8615\n",
      "60m 3s (- 108m 20s) (10700 35%) 6.0059\n",
      "60m 35s (- 107m 42s) (10800 36%) 5.4790\n",
      "61m 11s (- 107m 13s) (10900 36%) 6.0050\n",
      "61m 47s (- 106m 43s) (11000 36%) 5.6049\n",
      "62m 23s (- 106m 13s) (11100 37%) 5.9333\n",
      "62m 58s (- 105m 41s) (11200 37%) 5.8825\n",
      "63m 33s (- 105m 10s) (11300 37%) 6.0961\n",
      "64m 8s (- 104m 38s) (11400 38%) 5.8427\n",
      "64m 43s (- 104m 7s) (11500 38%) 5.7456\n",
      "65m 18s (- 103m 35s) (11600 38%) 5.7267\n",
      "65m 51s (- 103m 1s) (11700 39%) 5.6669\n",
      "66m 24s (- 102m 25s) (11800 39%) 5.8663\n",
      "67m 0s (- 101m 55s) (11900 39%) 5.8969\n",
      "67m 35s (- 101m 22s) (12000 40%) 5.8031\n",
      "68m 12s (- 100m 54s) (12100 40%) 6.0034\n",
      "68m 49s (- 100m 25s) (12200 40%) 6.0357\n",
      "69m 25s (- 99m 53s) (12300 41%) 6.0409\n",
      "70m 1s (- 99m 22s) (12400 41%) 6.1505\n",
      "70m 37s (- 98m 52s) (12500 41%) 6.0390\n",
      "71m 12s (- 98m 19s) (12600 42%) 5.9853\n",
      "71m 46s (- 97m 46s) (12700 42%) 6.0161\n",
      "72m 22s (- 97m 14s) (12800 42%) 6.0445\n",
      "72m 54s (- 96m 39s) (12900 43%) 5.8358\n",
      "73m 27s (- 96m 3s) (13000 43%) 5.6519\n",
      "74m 1s (- 95m 29s) (13100 43%) 6.0348\n",
      "74m 35s (- 94m 55s) (13200 44%) 5.6736\n",
      "75m 13s (- 94m 26s) (13300 44%) 5.9273\n",
      "75m 46s (- 93m 52s) (13400 44%) 5.9765\n",
      "76m 22s (- 93m 20s) (13500 45%) 5.8996\n",
      "76m 59s (- 92m 51s) (13600 45%) 6.2212\n",
      "77m 37s (- 92m 21s) (13700 45%) 6.2987\n",
      "78m 13s (- 91m 49s) (13800 46%) 5.9981\n",
      "78m 48s (- 91m 17s) (13900 46%) 6.1168\n",
      "79m 20s (- 90m 41s) (14000 46%) 5.8471\n",
      "79m 56s (- 90m 8s) (14100 47%) 5.8399\n",
      "80m 31s (- 89m 36s) (14200 47%) 6.2366\n",
      "81m 6s (- 89m 3s) (14300 47%) 5.7223\n",
      "81m 43s (- 88m 32s) (14400 48%) 6.1243\n",
      "82m 19s (- 88m 0s) (14500 48%) 5.8153\n",
      "82m 55s (- 87m 28s) (14600 48%) 5.9022\n",
      "83m 32s (- 86m 56s) (14700 49%) 6.0197\n",
      "84m 6s (- 86m 23s) (14800 49%) 5.7835\n",
      "84m 38s (- 85m 46s) (14900 49%) 5.4368\n",
      "85m 15s (- 85m 15s) (15000 50%) 6.0614\n",
      "85m 48s (- 84m 40s) (15100 50%) 5.5966\n",
      "86m 23s (- 84m 7s) (15200 50%) 5.9612\n",
      "87m 0s (- 83m 35s) (15300 51%) 5.8755\n",
      "87m 36s (- 83m 3s) (15400 51%) 5.8533\n",
      "88m 10s (- 82m 29s) (15500 51%) 5.6849\n",
      "88m 45s (- 81m 55s) (15600 52%) 5.7485\n",
      "89m 21s (- 81m 23s) (15700 52%) 5.6266\n",
      "89m 56s (- 80m 50s) (15800 52%) 5.7082\n",
      "90m 32s (- 80m 17s) (15900 53%) 5.8327\n",
      "91m 7s (- 79m 43s) (16000 53%) 5.7154\n",
      "91m 42s (- 79m 10s) (16100 53%) 5.9062\n",
      "92m 17s (- 78m 36s) (16200 54%) 5.8668\n",
      "92m 51s (- 78m 3s) (16300 54%) 5.8586\n",
      "93m 23s (- 77m 26s) (16400 54%) 5.4763\n",
      "93m 58s (- 76m 53s) (16500 55%) 5.8759\n",
      "94m 33s (- 76m 19s) (16600 55%) 6.1445\n",
      "95m 8s (- 75m 46s) (16700 55%) 5.7713\n",
      "95m 42s (- 75m 11s) (16800 56%) 5.8912\n",
      "96m 16s (- 74m 37s) (16900 56%) 5.8262\n",
      "96m 53s (- 74m 5s) (17000 56%) 5.9712\n",
      "97m 29s (- 73m 32s) (17100 56%) 5.7777\n",
      "98m 5s (- 72m 59s) (17200 57%) 5.7535\n",
      "98m 40s (- 72m 26s) (17300 57%) 5.9306\n",
      "99m 13s (- 71m 51s) (17400 57%) 5.9123\n",
      "99m 47s (- 71m 17s) (17500 58%) 5.6508\n",
      "100m 22s (- 70m 43s) (17600 58%) 5.7796\n",
      "100m 56s (- 70m 8s) (17700 59%) 5.6934\n",
      "101m 32s (- 69m 36s) (17800 59%) 5.9730\n",
      "102m 9s (- 69m 3s) (17900 59%) 5.9481\n",
      "102m 45s (- 68m 30s) (18000 60%) 5.9944\n",
      "103m 21s (- 67m 57s) (18100 60%) 5.7899\n",
      "103m 57s (- 67m 24s) (18200 60%) 6.0456\n",
      "104m 31s (- 66m 49s) (18300 61%) 6.0556\n",
      "105m 12s (- 66m 19s) (18400 61%) 5.9434\n",
      "105m 45s (- 65m 44s) (18500 61%) 5.9373\n",
      "106m 21s (- 65m 11s) (18600 62%) 5.7116\n",
      "106m 55s (- 64m 36s) (18700 62%) 5.6531\n",
      "107m 32s (- 64m 4s) (18800 62%) 5.9281\n",
      "108m 9s (- 63m 31s) (18900 63%) 5.7980\n",
      "108m 43s (- 62m 56s) (19000 63%) 5.8687\n",
      "109m 19s (- 62m 23s) (19100 63%) 6.0576\n",
      "109m 52s (- 61m 48s) (19200 64%) 5.9386\n",
      "110m 27s (- 61m 14s) (19300 64%) 5.9784\n",
      "111m 3s (- 60m 40s) (19400 64%) 5.6399\n",
      "111m 37s (- 60m 6s) (19500 65%) 6.1006\n",
      "112m 13s (- 59m 32s) (19600 65%) 5.8332\n",
      "112m 48s (- 58m 58s) (19700 65%) 5.7555\n",
      "113m 22s (- 58m 24s) (19800 66%) 5.7015\n",
      "113m 56s (- 57m 49s) (19900 66%) 5.7847\n",
      "114m 33s (- 57m 16s) (20000 66%) 5.7963\n",
      "115m 10s (- 56m 43s) (20100 67%) 5.9430\n",
      "115m 43s (- 56m 8s) (20200 67%) 5.5551\n",
      "116m 18s (- 55m 34s) (20300 67%) 5.8738\n",
      "116m 54s (- 55m 1s) (20400 68%) 6.2829\n",
      "117m 29s (- 54m 26s) (20500 68%) 5.7706\n",
      "118m 4s (- 53m 52s) (20600 68%) 5.8695\n",
      "118m 36s (- 53m 17s) (20700 69%) 5.7683\n",
      "119m 14s (- 52m 44s) (20800 69%) 5.8031\n",
      "119m 52s (- 52m 11s) (20900 69%) 5.8913\n",
      "120m 26s (- 51m 37s) (21000 70%) 5.9843\n",
      "121m 0s (- 51m 2s) (21100 70%) 6.0034\n",
      "121m 37s (- 50m 29s) (21200 70%) 5.9291\n",
      "122m 12s (- 49m 55s) (21300 71%) 5.7244\n",
      "122m 45s (- 49m 19s) (21400 71%) 5.6174\n",
      "123m 22s (- 48m 46s) (21500 71%) 6.0519\n",
      "123m 58s (- 48m 12s) (21600 72%) 5.9571\n",
      "124m 29s (- 47m 37s) (21700 72%) 5.6249\n",
      "125m 4s (- 47m 2s) (21800 72%) 6.0671\n",
      "125m 42s (- 46m 29s) (21900 73%) 5.9837\n",
      "126m 19s (- 45m 56s) (22000 73%) 5.8504\n",
      "126m 51s (- 45m 21s) (22100 73%) 5.6204\n",
      "127m 26s (- 44m 46s) (22200 74%) 5.6295\n",
      "128m 0s (- 44m 12s) (22300 74%) 5.6559\n",
      "128m 35s (- 43m 37s) (22400 74%) 5.7858\n",
      "129m 12s (- 43m 4s) (22500 75%) 5.9323\n",
      "129m 46s (- 42m 29s) (22600 75%) 5.9351\n",
      "130m 24s (- 41m 56s) (22700 75%) 5.9340\n",
      "130m 57s (- 41m 21s) (22800 76%) 5.6851\n",
      "131m 32s (- 40m 47s) (22900 76%) 5.6405\n",
      "132m 6s (- 40m 12s) (23000 76%) 5.6363\n",
      "132m 40s (- 39m 37s) (23100 77%) 5.6772\n",
      "133m 14s (- 39m 3s) (23200 77%) 5.8569\n",
      "133m 49s (- 38m 28s) (23300 77%) 5.7653\n",
      "134m 25s (- 37m 54s) (23400 78%) 5.9486\n",
      "135m 1s (- 37m 20s) (23500 78%) 5.9058\n",
      "135m 38s (- 36m 47s) (23600 78%) 5.6227\n",
      "136m 13s (- 36m 12s) (23700 79%) 5.7319\n",
      "136m 49s (- 35m 38s) (23800 79%) 5.7479\n",
      "137m 20s (- 35m 3s) (23900 79%) 5.6335\n",
      "137m 53s (- 34m 28s) (24000 80%) 5.7597\n",
      "138m 24s (- 33m 53s) (24100 80%) 5.5087\n",
      "138m 57s (- 33m 18s) (24200 80%) 5.7259\n",
      "139m 33s (- 32m 44s) (24300 81%) 5.7279\n",
      "140m 11s (- 32m 10s) (24400 81%) 5.9883\n",
      "140m 45s (- 31m 35s) (24500 81%) 5.8545\n",
      "141m 20s (- 31m 1s) (24600 82%) 5.6887\n",
      "141m 55s (- 30m 27s) (24700 82%) 6.1098\n",
      "142m 33s (- 29m 53s) (24800 82%) 5.7845\n",
      "143m 6s (- 29m 18s) (24900 83%) 5.8699\n",
      "143m 44s (- 28m 44s) (25000 83%) 5.8998\n",
      "144m 17s (- 28m 10s) (25100 83%) 5.7104\n",
      "144m 56s (- 27m 36s) (25200 84%) 5.7508\n",
      "145m 34s (- 27m 2s) (25300 84%) 5.9465\n",
      "146m 8s (- 26m 28s) (25400 84%) 5.6783\n",
      "146m 44s (- 25m 53s) (25500 85%) 6.0268\n",
      "147m 19s (- 25m 19s) (25600 85%) 5.9651\n",
      "147m 52s (- 24m 44s) (25700 85%) 5.9375\n",
      "148m 26s (- 24m 9s) (25800 86%) 5.5745\n",
      "149m 0s (- 23m 35s) (25900 86%) 5.6979\n",
      "149m 37s (- 23m 1s) (26000 86%) 5.9677\n",
      "150m 13s (- 22m 26s) (26100 87%) 5.9021\n",
      "150m 48s (- 21m 52s) (26200 87%) 5.8781\n",
      "151m 25s (- 21m 18s) (26300 87%) 5.8650\n",
      "152m 1s (- 20m 43s) (26400 88%) 6.0598\n",
      "152m 34s (- 20m 9s) (26500 88%) 5.9888\n",
      "153m 12s (- 19m 34s) (26600 88%) 5.9745\n",
      "153m 48s (- 19m 0s) (26700 89%) 6.0962\n",
      "154m 21s (- 18m 25s) (26800 89%) 5.8200\n",
      "154m 54s (- 17m 51s) (26900 89%) 5.6449\n",
      "155m 31s (- 17m 16s) (27000 90%) 5.7910\n",
      "156m 7s (- 16m 42s) (27100 90%) 5.8891\n",
      "156m 44s (- 16m 8s) (27200 90%) 6.0025\n",
      "157m 21s (- 15m 33s) (27300 91%) 5.9223\n",
      "157m 57s (- 14m 59s) (27400 91%) 6.0017\n",
      "158m 31s (- 14m 24s) (27500 91%) 5.8337\n",
      "159m 8s (- 13m 50s) (27600 92%) 5.7966\n",
      "159m 39s (- 13m 15s) (27700 92%) 5.8083\n",
      "160m 14s (- 12m 40s) (27800 92%) 5.9886\n",
      "160m 49s (- 12m 6s) (27900 93%) 5.7903\n",
      "161m 23s (- 11m 31s) (28000 93%) 5.6405\n",
      "161m 56s (- 10m 56s) (28100 93%) 5.3154\n",
      "162m 33s (- 10m 22s) (28200 94%) 5.6671\n",
      "163m 8s (- 9m 48s) (28300 94%) 5.7996\n",
      "163m 43s (- 9m 13s) (28400 94%) 5.7272\n",
      "164m 18s (- 8m 38s) (28500 95%) 5.8109\n",
      "164m 55s (- 8m 4s) (28600 95%) 5.9026\n",
      "165m 29s (- 7m 29s) (28700 95%) 6.0083\n",
      "166m 4s (- 6m 55s) (28800 96%) 6.0539\n",
      "166m 38s (- 6m 20s) (28900 96%) 5.7426\n",
      "167m 16s (- 5m 46s) (29000 96%) 6.1093\n",
      "167m 50s (- 5m 11s) (29100 97%) 5.5821\n",
      "168m 27s (- 4m 36s) (29200 97%) 5.8998\n",
      "169m 0s (- 4m 2s) (29300 97%) 5.8479\n",
      "169m 40s (- 3m 27s) (29400 98%) 5.9769\n",
      "170m 16s (- 2m 53s) (29500 98%) 5.7258\n",
      "170m 52s (- 2m 18s) (29600 98%) 5.7422\n",
      "171m 26s (- 1m 43s) (29700 99%) 5.6010\n",
      "172m 2s (- 1m 9s) (29800 99%) 5.9815\n",
      "172m 38s (- 0m 34s) (29900 99%) 5.7250\n",
      "173m 15s (- 0m 0s) (30000 100%) 6.0214\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "\n",
    "#If using K-Folds, there is a need to change \n",
    "#train_pairs to train_pairs_n, where n represents which fold to use\n",
    "#test_pairs to test_pairs_n, where n represents which fold to use\n",
    "#input_lang to input_lang_n, where n represents which fold to use\n",
    "#output_lang to output_lang_n, where n represents which fold to use\n",
    "\n",
    "#If using K-Folds, change input_lang to input_lang_1/input_lang_2/input_lang_3/input_lang_4/input_lang_5 accordingly\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "\n",
    "#If using K-Folds, change output_lang to output_lang_1/output_lang_2/output_lang_3/output_lang_4/output_lang_5 accordingly\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 30000, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 6338853,
     "status": "ok",
     "timestamp": 1615846027335,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "qToSOg3C5Tyf"
   },
   "outputs": [],
   "source": [
    "# evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 6338852,
     "status": "ok",
     "timestamp": 1615846027336,
     "user": {
      "displayName": "Rollux Alex",
      "photoUrl": "",
      "userId": "11504799350464529649"
     },
     "user_tz": -480
    },
    "id": "JZwVsc8e5Tyg"
   },
   "outputs": [],
   "source": [
    "#Greedy Decoder\n",
    "start_time = time.time()\n",
    "scoreGreedy = evaluateBleu(encoder1, attn_decoder1)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(scoreGreedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "vnmenlJ25Tyg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 45881.20223402977 seconds ---\n",
      "0.0015078081467405809\n"
     ]
    }
   ],
   "source": [
    "#Beam Search Decoder\n",
    "start_time = time.time()\n",
    "score = evaluateBleu_beam_search(encoder1, attn_decoder1, 2)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "e5C-jxBC5Tyb",
    "r2dUapv-5Tyc",
    "wknZPW4E5Tyd",
    "SNn6-sQ85Tye",
    "3UXklreo5Tyg"
   ],
   "name": "Try2Q3_ru.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
